use crate::errors::ExtractResult;
use crate::tika;
use crate::tika::JReaderInputStream;
use crate::{OfficeParserConfig, PdfParserConfig, TesseractOcrConfig, MMAP_THRESHOLD};
use std::collections::HashMap;
use std::path::Path;
use strum_macros::{Display, EnumString};

#[cfg(feature = "mmap")]
use memmap2::MmapOptions;

#[cfg(feature = "parallel")]
use rayon::prelude::*;

/// Metadata type alias
pub type Metadata = HashMap<String, Vec<String>>;

/// CharSet enum of all supported encodings
#[derive(Debug, Clone, Default, Copy, PartialEq, Eq, Hash, Display, EnumString)]
#[allow(non_camel_case_types)]
pub enum CharSet {
    #[default]
    UTF_8,
    US_ASCII,
    UTF_16BE,
}

/// StreamReader implements std::io::Read
///
/// Can be used to perform buffered reading. For example:
/// ```rust
/// use extractous::{CharSet, Extractor};
/// use std::io::BufReader;
/// use std::io::prelude::*;
///
/// let extractor = Extractor::new();
/// let (reader, metadata) = extractor.extract_file("README.md").unwrap();
///
/// let mut buf_reader = BufReader::new(reader);
/// let mut content = String::new();
/// buf_reader.read_to_string(&mut content).unwrap();
/// println!("{}", content);
/// ```
///
pub struct StreamReader {
    pub(crate) inner: JReaderInputStream,
}

impl std::io::Read for StreamReader {
    fn read(&mut self, buf: &mut [u8]) -> std::io::Result<usize> {
        self.inner.read(buf)
    }
}

/// Extractor for extracting text from different file formats
///
/// The Extractor uses the builder pattern to set configurations. This allows configuring and
/// extracting text in one line. For example
/// ```rust
/// use extractous::{CharSet, Extractor};
/// let (text, metadata) = Extractor::new()
///             .set_extract_string_max_length(1000)
///             .extract_file_to_string("README.md")
///             .unwrap();
/// println!("{}", text);
/// ```
///
#[derive(Debug, Clone)]
pub struct Extractor {
    extract_string_max_length: i32,
    encoding: CharSet,
    pdf_config: PdfParserConfig,
    office_config: OfficeParserConfig,
    ocr_config: TesseractOcrConfig,
    xml_output: bool,
    // Performance optimization settings
    use_mmap: bool,
    mmap_threshold: usize,
    enable_parallel: bool,
    use_pure_rust: bool,
    enable_text_cleaning: bool,
}

impl Default for Extractor {
    fn default() -> Self {
        Self {
            extract_string_max_length: 500_000, // 500KB
            encoding: CharSet::UTF_8,
            pdf_config: PdfParserConfig::default(),
            office_config: OfficeParserConfig::default(),
            ocr_config: TesseractOcrConfig::default(),
            xml_output: false,
            // Enable optimizations by default when features are available
            use_mmap: cfg!(feature = "mmap"),
            mmap_threshold: MMAP_THRESHOLD,
            enable_parallel: cfg!(feature = "parallel"),
            use_pure_rust: cfg!(feature = "pure-rust"),
            enable_text_cleaning: false, // Disabled by default to avoid overhead
        }
    }
}

impl Extractor {
    pub fn new() -> Self {
        Self::default()
    }

    /// Set the maximum length of the extracted text. Used only for extract_to_string functions
    /// Default: 500_000
    pub fn set_extract_string_max_length(mut self, max_length: i32) -> Self {
        self.extract_string_max_length = max_length;
        self
    }

    /// Set the encoding to use for when extracting text to a stream.
    /// Not used for extract_to_string functions.
    /// Default: CharSet::UTF_8
    pub fn set_encoding(mut self, encoding: CharSet) -> Self {
        self.encoding = encoding;
        self
    }

    /// Set the configuration for the PDF parser
    pub fn set_pdf_config(mut self, config: PdfParserConfig) -> Self {
        self.pdf_config = config;
        self
    }

    /// Set the configuration for the Office parser
    pub fn set_office_config(mut self, config: OfficeParserConfig) -> Self {
        self.office_config = config;
        self
    }

    /// Set the configuration for the Tesseract OCR
    pub fn set_ocr_config(mut self, config: TesseractOcrConfig) -> Self {
        self.ocr_config = config;
        self
    }

    /// Set the configuration for the parse as xml
    pub fn set_xml_output(mut self, xml_output: bool) -> Self {
        self.xml_output = xml_output;
        self
    }

    /// Enable or disable memory-mapped file I/O for large files
    /// This can significantly improve performance for large files
    pub fn set_use_mmap(mut self, use_mmap: bool) -> Self {
        self.use_mmap = use_mmap;
        self
    }

    /// Set the threshold for using memory-mapped I/O
    /// Files larger than this size will use memory mapping
    pub fn set_mmap_threshold(mut self, threshold: usize) -> Self {
        self.mmap_threshold = threshold;
        self
    }

    /// Enable or disable parallel processing for batch operations
    pub fn set_enable_parallel(mut self, enable_parallel: bool) -> Self {
        self.enable_parallel = enable_parallel;
        self
    }

    /// Enable or disable pure Rust parsers for better performance
    /// When enabled, uses pure Rust implementations for supported formats
    /// Falls back to Tika for unsupported formats
    pub fn set_use_pure_rust(mut self, use_pure_rust: bool) -> Self {
        self.use_pure_rust = use_pure_rust;
        self
    }

    /// Enable or disable SIMD-optimized text cleaning
    /// When enabled, applies text normalization and cleaning for better quality
    pub fn set_enable_text_cleaning(mut self, enable_text_cleaning: bool) -> Self {
        self.enable_text_cleaning = enable_text_cleaning;
        self
    }

    /// Extracts text from a file path. Returns a tuple with stream of the extracted text and metadata.
    /// the stream is decoded using the extractor's `encoding`
    ///
    /// Performance optimizations:
    /// - Uses pure Rust parsers for supported formats when enabled (2-3x faster)
    /// - Uses memory-mapped I/O for large files when enabled
    /// - Adaptive buffer sizing based on file size
    /// - Falls back to Tika for unsupported formats
    pub fn extract_file(&self, file_path: &str) -> ExtractResult<(StreamReader, Metadata)> {
        // Try pure Rust parsers first for maximum performance
        #[cfg(feature = "pure-rust")]
        if self.use_pure_rust {
            if let Ok((text, metadata)) = self.try_pure_rust_extraction(file_path) {
                // Convert string result to StreamReader for API compatibility
                return Ok((self.string_to_stream_reader(text), metadata));
            }
        }

        #[cfg(feature = "mmap")]
        if self.use_mmap {
            if let Ok(file_size) = std::fs::metadata(file_path).map(|m| m.len() as usize) {
                if file_size > self.mmap_threshold {
                    return self.extract_file_with_mmap(file_path);
                }
            }
        }

        // Fallback to standard Tika extraction
        tika::parse_file(
            file_path,
            &self.encoding,
            &self.pdf_config,
            &self.office_config,
            &self.ocr_config,
            self.xml_output,
        )
    }

    /// Extracts text from a byte buffer. Returns a tuple with stream of the extracted text and metadata.
    /// the stream is decoded using the extractor's `encoding`
    pub fn extract_bytes(&self, buffer: &[u8]) -> ExtractResult<(StreamReader, Metadata)> {
        tika::parse_bytes(
            buffer,
            &self.encoding,
            &self.pdf_config,
            &self.office_config,
            &self.ocr_config,
            self.xml_output,
        )
    }

    /// Extracts text from an url. Returns a tuple with stream of the extracted text and metadata.
    /// the stream is decoded using the extractor's `encoding`
    pub fn extract_url(&self, url: &str) -> ExtractResult<(StreamReader, Metadata)> {
        tika::parse_url(
            url,
            &self.encoding,
            &self.pdf_config,
            &self.office_config,
            &self.ocr_config,
            self.xml_output,
        )
    }

    /// Extracts text from a file path. Returns a tuple with string that is of maximum length
    /// of the extractor's `extract_string_max_length` and metadata.
    ///
    /// Performance optimizations:
    /// - Uses pure Rust parsers when available for 2-3x speedup
    /// - Applies optimized text processing when enabled
    /// - Smart text truncation that respects word boundaries
    pub fn extract_file_to_string(&self, file_path: &str) -> ExtractResult<(String, Metadata)> {
        // Try pure Rust parsers first for maximum performance
        #[cfg(feature = "pure-rust")]
        if self.use_pure_rust {
            if let Ok((text, metadata)) = self.try_pure_rust_extraction(file_path) {
                return Ok(self.post_process_text(text, metadata));
            }
        }

        // Standard Tika extraction (optimized through buffer improvements)
        let (text, metadata) = tika::parse_file_to_string(
            file_path,
            self.extract_string_max_length,
            &self.pdf_config,
            &self.office_config,
            &self.ocr_config,
            self.xml_output,
        )?;

        Ok(self.post_process_text(text, metadata))
    }



    /// Extracts text from a byte buffer. Returns a tuple with string that is of maximum length
    /// of the extractor's `extract_string_max_length` and metadata.
    pub fn extract_bytes_to_string(&self, buffer: &[u8]) -> ExtractResult<(String, Metadata)> {
        let (text, metadata) = tika::parse_bytes_to_string(
            buffer,
            self.extract_string_max_length,
            &self.pdf_config,
            &self.office_config,
            &self.ocr_config,
            self.xml_output,
        )?;

        Ok(self.post_process_text(text, metadata))
    }

    /// Extracts text from a URL. Returns a tuple with string that is of maximum length
    /// of the extractor's `extract_string_max_length` and metadata.
    pub fn extract_url_to_string(&self, url: &str) -> ExtractResult<(String, Metadata)> {
        let (text, metadata) = tika::parse_url_to_string(
            url,
            self.extract_string_max_length,
            &self.pdf_config,
            &self.office_config,
            &self.ocr_config,
            self.xml_output,
        )?;

        Ok(self.post_process_text(text, metadata))
    }

    /// Memory-mapped file extraction for improved performance on large files
    #[cfg(feature = "mmap")]
    fn extract_file_with_mmap(&self, file_path: &str) -> ExtractResult<(StreamReader, Metadata)> {
        use std::fs::File;

        let file = File::open(file_path)
            .map_err(|e| crate::errors::Error::IoError(e.to_string()))?;

        let mmap = unsafe { MmapOptions::new().map(&file) }
            .map_err(|e| crate::errors::Error::IoError(e.to_string()))?;

        // Use the memory-mapped data as a byte slice for extraction
        self.extract_bytes(&mmap)
    }

    /// Extract multiple files in parallel (when parallel feature is enabled)
    #[cfg(feature = "parallel")]
    pub fn extract_files_parallel<P: AsRef<Path> + Sync>(
        &self,
        file_paths: &[P],
    ) -> Vec<ExtractResult<(String, Metadata)>> {
        if self.enable_parallel {
            file_paths
                .par_iter()
                .map(|path| self.extract_file_to_string(path.as_ref().to_str().unwrap_or("")))
                .collect()
        } else {
            file_paths
                .iter()
                .map(|path| self.extract_file_to_string(path.as_ref().to_str().unwrap_or("")))
                .collect()
        }
    }

    /// Extract multiple files sequentially (fallback when parallel feature is disabled)
    #[cfg(not(feature = "parallel"))]
    pub fn extract_files_parallel<P: AsRef<Path>>(
        &self,
        file_paths: &[P],
    ) -> Vec<ExtractResult<(String, Metadata)>> {
        file_paths
            .iter()
            .map(|path| self.extract_file_to_string(path.as_ref().to_str().unwrap_or("")))
            .collect()
    }

    /// Try pure Rust extraction for supported formats
    #[cfg(feature = "pure-rust")]
    fn try_pure_rust_extraction(&self, file_path: &str) -> ExtractResult<(String, Metadata)> {
        let pure_extractor = crate::pure_rust_parsers::PureRustExtractor::with_max_length(
            self.extract_string_max_length as usize
        );
        pure_extractor.extract_file(file_path)
    }

    /// Convert string to StreamReader for API compatibility
    /// This is a temporary workaround - in practice, pure Rust extraction
    /// should use the extract_file_to_string method for best performance
    #[allow(dead_code)]
    fn string_to_stream_reader(&self, text: String) -> StreamReader {
        // Convert back to bytes and use extract_bytes
        // This maintains API compatibility but isn't optimal
        let bytes = text.into_bytes();
        match self.extract_bytes(&bytes) {
            Ok((stream, _)) => stream,
            Err(_) => {
                // This shouldn't happen in normal operation
                // If it does, we have a serious issue with the extraction pipeline
                panic!("Failed to create StreamReader from extracted text - this indicates a bug in the extraction logic")
            }
        }
    }

    /// Post-process extracted text with minimal overhead optimizations
    fn post_process_text(&self, mut text: String, mut metadata: Metadata) -> (String, Metadata) {
        if self.enable_text_cleaning {
            // Only apply expensive operations if text is large enough to benefit
            if text.len() > 5000 { // Increased threshold to reduce overhead
                // Apply lightweight text cleaning only
                text = crate::simd_text::normalize_whitespace(&text);
                metadata.insert("Text-Processing".to_string(), vec!["lightweight".to_string()]);
            }

            // Smart truncation only if needed
            if text.len() > self.extract_string_max_length as usize {
                text = crate::simd_text::truncate_text_smart(&text, self.extract_string_max_length as usize);
            }
        }

        (text, metadata)
    }

}

#[cfg(test)]
mod tests {
    use super::StreamReader;
    use crate::Extractor;
    use std::fs::File;
    use std::io::BufReader;
    use std::io::{self, Read};
    use std::str;

    const TEST_FILE: &str = "README.md";

    const TEST_URL: &str = "https://www.google.com/";

    fn expected_content() -> String {
        let mut file = File::open(TEST_FILE).unwrap();
        let mut content = String::new();
        file.read_to_string(&mut content).unwrap();
        content
    }

    #[test]
    fn extract_file_to_string_test() {
        // Prepare expected_content
        let expected_content = expected_content();

        // Parse the files using extractous with text cleaning disabled for this test
        // to maintain compatibility with existing expected output
        let extractor = Extractor::new().set_enable_text_cleaning(false);
        let result = extractor.extract_file_to_string(TEST_FILE);
        let (content, metadata) = result.unwrap();
        assert_eq!(content.trim(), expected_content.trim());
        assert!(
            metadata.len() > 0,
            "Metadata should contain at least one entry"
        );
    }

    fn read_content_from_stream(stream: StreamReader) -> String {
        let mut reader = BufReader::new(stream);
        let mut buffer = Vec::new();
        reader.read_to_end(&mut buffer).unwrap();

        let content = String::from_utf8(buffer).unwrap();
        content
    }

    #[test]
    fn extract_file_test() {
        // Prepare expected_content
        let expected_content = expected_content();

        // Parse the files using extractous
        let extractor = Extractor::new();
        let result = extractor.extract_file(TEST_FILE);
        let (reader, metadata) = result.unwrap();
        let content = read_content_from_stream(reader);

        assert_eq!(content.trim(), expected_content.trim());
        assert!(
            metadata.len() > 0,
            "Metadata should contain at least one entry"
        );
    }

    fn read_file_as_bytes(path: &str) -> io::Result<Vec<u8>> {
        let mut file = File::open(path)?;
        let mut buffer = Vec::new();
        file.read_to_end(&mut buffer)?;
        Ok(buffer)
    }

    #[test]
    fn extract_bytes_test() {
        // Prepare expected_content
        let expected_content = expected_content();

        // Parse the bytes using extractous
        let file_bytes = read_file_as_bytes(TEST_FILE).unwrap();
        let extractor = Extractor::new();
        let result = extractor.extract_bytes(&file_bytes);
        let (reader, metadata) = result.unwrap();
        let content = read_content_from_stream(reader);

        assert_eq!(content.trim(), expected_content.trim());
        assert!(
            metadata.len() > 0,
            "Metadata should contain at least one entry"
        );
    }

    #[test]
    fn extract_url_test() {
        // Parse url by extractous
        let extractor = Extractor::new();
        let result = extractor.extract_url(&TEST_URL);
        let (reader, metadata) = result.unwrap();
        let content = read_content_from_stream(reader);

        assert!(content.contains("Google"));
        assert!(
            metadata.len() > 0,
            "Metadata should contain at least one entry"
        );
    }

    #[test]
    fn extract_file_to_xml_test() {
        // Parse the files using extractous
        let extractor = Extractor::new().set_xml_output(true);
        let result = extractor.extract_file_to_string(TEST_FILE);
        let (content, metadata) = result.unwrap();
        assert!(
            content.len() > 0,
            "Metadata should contain at least one entry"
        );
        assert!(
            metadata.len() > 0,
            "Metadata should contain at least one entry"
        );
    }
}
